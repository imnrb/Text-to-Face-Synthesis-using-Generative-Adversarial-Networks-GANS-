# Text-to-Face Synthesis using Generative Adversarial Networks(GANS)
Objective: To generate high-resolution, lifelike facial images using user-given text descriptions
without any disentanglements using GANs.

GANs are generative models which can produce new data instances that resemble
our training data. The function of the Generator is to produce samples that are similar to
those from the problem domain while that of the Discriminator is to identify whether the
given sample is generated by the generator (fake) or from the problem domain (real).
The term adversarial in this network arises from the fact both these networks are engaged
in a competitive minimax game wherein each network tries to outperform the other.
The discriminator maximizes the probability of assigning accurate labels to the examples while
The generator tries to minimize the probability of the Discriminator correctly classifying its
generated examples as fake.


Deep Fusion GAN (DFGAN) is a text-to-image generative model which uses a simplified backbone architecture than Attngan with a single Generator and Discriminator network
along with a pre-trained Bi-Directional LSTM as its text encoder


# Architecture of DFGAN Model
![image](https://github.com/imnrb/Text-to-Face-Synthesis-using-Generative-Adversarial-Networks-GANS-/assets/70696174/ea884e38-ed86-4d14-b514-2851ed505771)


Below is one such example which we ran on our environment

![Capture](https://github.com/imnrb/Text-to-Face-Synthesis-using-Generative-Adversarial-Networks-GANS-/assets/67147637/bd555064-2c33-4f8d-bc90-84bb158bcb55)


Text-to-face generation using Deep Fusion GAN (DFGAN) is a promising approach for
synthesizing high-quality realistic facial images from textual descriptions. This technology
has the potential to revolutionize a wide range of applications, from creating lifelike avatars
in video games and virtual reality environments to generate images of missing persons in
forensic investigations.
